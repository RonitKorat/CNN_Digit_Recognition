{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    show_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.imshow(show_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(type='cuda',index=0)\n",
    "else:\n",
    "    device=torch.device(type='cpu',index=0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agricultural': 0, 'airplane': 1, 'baseballdiamond': 2, 'beach': 3, 'buildings': 4, 'chaparral': 5, 'denseresidential': 6, 'forest': 7, 'freeway': 8, 'golfcourse': 9, 'harbor': 10, 'intersection': 11, 'mediumresidential': 12, 'mobilehomepark': 13, 'overpass': 14, 'parkinglot': 15, 'river': 16, 'runway': 17, 'sparseresidential': 18, 'storagetanks': 19, 'tenniscourt': 20}\n",
      "torch.Size([2100, 3, 256, 256]) torch.Size([2100])\n",
      "torch.FloatTensor torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "base_dir = 'R:\\\\NIRMA SEM-V\\\\cvdl\\\\Digit_Recognition_using_CNN\\\\UCMerced_LandUse\\\\Images'\n",
    "\n",
    "list_folders = os.listdir(base_dir)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "label_map = {folder: idx for idx, folder in enumerate(list_folders)}\n",
    "\n",
    "print(label_map)\n",
    "\n",
    "for folder in list_folders:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    list_images = os.listdir(folder_path)\n",
    "    \n",
    "    for image_name in list_images:\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        if img is None:\n",
    "            print(f'Image {image_name} not loaded in folder {folder}')\n",
    "            continue\n",
    "        \n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        img = img / 255.0  \n",
    "        \n",
    "        img_tensor = torch.from_numpy(np.transpose(img, (2, 0, 1))).float()   \n",
    "        images.append(img_tensor)\n",
    "        labels.append(label_map[folder])\n",
    "\n",
    "# Convert the lists to Tensors\n",
    "images = torch.stack(images)\n",
    "labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "print(images.shape, labels.shape)\n",
    "print(images[0].type(), labels[0].type())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1680, 3, 256, 256]) torch.Size([420, 3, 256, 256]) torch.Size([1680]) torch.Size([420])\n",
      "53 14\n"
     ]
    }
   ],
   "source": [
    "#spliting into train and test\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_images, train_labels,)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_images, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(train_images.shape, test_images.shape, train_labels.shape, test_labels.shape)\n",
    "print(len(train_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,32,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "        self.conv2=nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "\n",
    "        self.conv3=nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "   \n",
    "        self.feature_size = self._get_conv_output((3, 256, 256))\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 21)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "        output_feat = self._forward_features(input)\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.pool(x)\n",
    "\n",
    "        x=self.conv2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.pool(x)\n",
    "\n",
    "        x=self.conv3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.pool(x)\n",
    "\n",
    "        # x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.dropout(x)\n",
    "        # x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    acc = 0  # Keep track of cumulative accuracy\n",
    "    total_loss = 0  # Keep track of total loss\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.long())\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update accuracy and loss\n",
    "        acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss_val = loss.item()\n",
    "            current = batch * len(X)\n",
    "            print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    # Calculate and print average accuracy and loss for the epoch\n",
    "    acc /= size\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Accuracy for that epoch: {(100*acc):>7f}, Avg loss: {avg_loss:>7f}\")\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y.long()).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 1\n",
      "loss: 2.725936  [    0/ 1680]\n",
      "Accuracy: 0.223214, Avg loss: 2.522833\n",
      "Epoch No: 2\n",
      "loss: 1.857868  [    0/ 1680]\n",
      "Accuracy: 0.397024, Avg loss: 2.002101\n",
      "Epoch No: 3\n",
      "loss: 1.778817  [    0/ 1680]\n",
      "Accuracy: 0.572619, Avg loss: 1.411816\n",
      "Epoch No: 4\n",
      "loss: 0.904564  [    0/ 1680]\n",
      "Accuracy: 0.692857, Avg loss: 1.021756\n",
      "Epoch No: 5\n",
      "loss: 0.597796  [    0/ 1680]\n",
      "Accuracy: 0.804167, Avg loss: 0.629551\n",
      "Test Accuracy: 50.2%, Avg loss: 0.066042 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "for i in range(epochs):\n",
    "    print(\"Epoch No:\", i + 1)\n",
    "    train_one_epoch(train_loader, model, loss_fn, optimizer)\n",
    "\n",
    "test_one_epoch(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
